{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dhara3078/Hack-The-Tank-YFD-project/blob/main/vgg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mS2ZNa3F5iOR"
      },
      "outputs": [],
      "source": [
        " import warnings\n",
        " import os\n",
        " import shutil\n",
        " import glob\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mounting the drive\n"
      ],
      "metadata": {
        "id": "N_EDdWKTx6eb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiKiK24CG3DO",
        "outputId": "4b2a380c-0241-44c0-c5a3-2d088d7b1dca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# class\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Vo0QaO4Yx_zJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJViGdf06kQz"
      },
      "outputs": [],
      "source": [
        "CLASS = ['flat', 'high', 'normal']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xD-yFXZn-m4P"
      },
      "source": [
        "# model building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJub2lyY-mCx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras .models import Model\n",
        "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import keras\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_ck947M_S-5"
      },
      "outputs": [],
      "source": [
        "base_model = InceptionV3(input_shape=(256, 256, 3), include_top= False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RptO4-DU_TQg"
      },
      "outputs": [],
      "source": [
        "# --------------------------\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Set the desired image size\n",
        "new_size = (256, 256)\n",
        "\n",
        "# Loop over all image files in a directory and resize them\n",
        "for filename in os.listdir('/content/drive/MyDrive/DATASET/flat'):\n",
        "    if filename.endswith('.jpg') or filename.endswith('.png'): # Modify this condition based on the file extensions of your images\n",
        "        # Open the image file using PIL\n",
        "        img = Image.open(os.path.join('/content/drive/MyDrive/DATASET/flat', filename))\n",
        "        \n",
        "        # Resize the image to the desired size\n",
        "        img = img.resize(new_size)\n",
        "        \n",
        "        # Save the resized image to a new file\n",
        "        img.save(os.path.join('/content/drive/MyDrive/DATASET_RESIZED/flat', filename))\n",
        "\n",
        "for filename in os.listdir('/content/drive/MyDrive/DATASET/normal'):\n",
        "    if filename.endswith('.jpg') or filename.endswith('.png'): # Modify this condition based on the file extensions of your images\n",
        "        # Open the image file using PIL\n",
        "        img = Image.open(os.path.join('/content/drive/MyDrive/DATASET/normal', filename))\n",
        "        \n",
        "        # Resize the image to the desired size\n",
        "        img = img.resize(new_size)\n",
        "        \n",
        "        # Save the resized image to a new file\n",
        "        img.save(os.path.join('/content/drive/MyDrive/DATASET_RESIZED/normal', filename))\n",
        "for filename in os.listdir('/content/drive/MyDrive/DATASET/high'):\n",
        "    if filename.endswith('.jpg') or filename.endswith('.png'): # Modify this condition based on the file extensions of your images\n",
        "        # Open the image file using PIL\n",
        "        img = Image.open(os.path.join('/content/drive/MyDrive/DATASET/high', filename))\n",
        "        \n",
        "        # Resize the image to the desired size\n",
        "        img = img.resize(new_size)\n",
        "        \n",
        "        # Save the resized image to a new file\n",
        "        img.save(os.path.join('/content/drive/MyDrive/DATASET_RESIZED/high', filename))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyheif\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "def heic_to_jpg(file_path):\n",
        "    # Open the HEIC file\n",
        "    heif_file = pyheif.read(file_path)\n",
        "\n",
        "    # Convert to PIL Image object\n",
        "    image = Image.frombytes(\n",
        "        heif_file.mode,\n",
        "        heif_file.size,\n",
        "        heif_file.data,\n",
        "        \"raw\",\n",
        "        heif_file.mode,\n",
        "        heif_file.stride,\n",
        "    )\n",
        "\n",
        "    # Save as JPG file with the same name\n",
        "    file_name = os.path.splitext(os.path.basename(file_path))[0]\n",
        "    new_file_path = os.path.join(os.path.dirname(file_path), file_name + \".jpg\")\n",
        "    image.save(new_file_path, \"JPEG\")\n",
        "    print(f\"{file_path} converted to {new_file_path}\")\n"
      ],
      "metadata": {
        "id": "LH40ztiDFUmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyheif"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiOIIBJnF2OW",
        "outputId": "69c04578-4c16-4cf3-a076-482e53ee0772"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyheif in /usr/local/lib/python3.9/dist-packages (0.7.1)\n",
            "Requirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from pyheif) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.0.0->pyheif) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGC-ZxeBFydS",
        "outputId": "11baef1e-5316-4dde-fa74-fa71872ad0e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_192 (Conv2D)         (None, 254, 254, 26)      728       \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPoolin  (None, 127, 127, 26)     0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_193 (Conv2D)         (None, 125, 125, 64)      15040     \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPoolin  (None, 62, 62, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 246016)            0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 256)               62980352  \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,996,377\n",
            "Trainable params: 62,996,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# Define the model architecture\n",
        "model = Sequential()\n",
        "model.add(Conv2D(26, kernel_size=(3, 3), activation='relu', input_shape=(256, 256, 3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(3, activation='linear'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xG4lSMLWWMfR",
        "outputId": "4c96f5d4-3ee0-4f5b-806e-91495c1ec155"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 859 images belonging to 3 classes.\n",
            "Found 366 images belonging to 3 classes.\n",
            "{'flat': 0, 'high': 1, 'normal': 2}\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Set up the ImageDataGenerator with data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.3)\n",
        "\n",
        "# Set up the training and validation data generators\n",
        "train_data = train_datagen.flow_from_directory(\n",
        "    directory='/content/drive/MyDrive/DATASET_RESIZED/',\n",
        "    target_size=(256, 256),\n",
        "    batch_size=26,\n",
        "    class_mode='categorical',\n",
        "    subset='training')\n",
        "\n",
        "val_data = train_datagen.flow_from_directory(\n",
        "    directory='/content/drive/MyDrive/DATASET_RESIZED/',\n",
        "    target_size=(256, 256),\n",
        "    batch_size=26,\n",
        "    class_mode='categorical',\n",
        "    subset='validation')\n",
        "\n",
        "\n",
        "print(train_data.class_indices)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6rPB8RIP4ds"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QH4yR-JYTpQc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22e73fbc-10d8-4076-e970-21cdc07ec646"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1225 files belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "data = tf.keras.utils.image_dataset_from_directory('/content/drive/MyDrive/DATASET_RESIZED/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smmXs-aiaJjQ",
        "outputId": "41c7f273-2682-4b33-c91c-d8ada7e957a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<keras.callbacks.ModelCheckpoint object at 0x7f55895ef6d0>\n",
            "./best_model.h5\n"
          ]
        }
      ],
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# Define the file path for saving the model weights\n",
        "filepath = \"./best_model.h5\"\n",
        "\n",
        "# Define the checkpoint callback to save the model weights\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='accurary', verbose=1, save_best_only=False, mode='min')\n",
        "\n",
        "print(checkpoint);\n",
        "print(filepath)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZDPp3jDP6E2"
      },
      "outputs": [],
      "source": [
        "from tensorflow.compat.v1 import ConfigProto\n",
        "from tensorflow.compat.v1 import InteractiveSession\n",
        "\n",
        "config = ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = InteractiveSession(config=config)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t_img,label=train_data.next()\n",
        "t_img.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cp4N-2xpn9a-",
        "outputId": "6f1ff4bf-04a8-45a1-fa8e-21426dc526bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26, 256, 256, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4RemxhbVf2I",
        "outputId": "9a8e64e0-29c4-4ee1-a5f1-a0374edebc89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "34/34 [==============================] - ETA: 0s - loss: 9.8822 - accuracy: 0.3434\n",
            "Epoch 1: saving model to ./best_model.h5\n",
            "34/34 [==============================] - 46s 1s/step - loss: 9.8822 - accuracy: 0.3434\n",
            "Epoch 2/5\n",
            "34/34 [==============================] - ETA: 0s - loss: 10.1662 - accuracy: 0.3333\n",
            "Epoch 2: saving model to ./best_model.h5\n",
            "34/34 [==============================] - 24s 717ms/step - loss: 10.1662 - accuracy: 0.3333\n"
          ]
        }
      ],
      "source": [
        "train_data.class_indices\n",
        "history = model.fit(train_data,epochs=5,callbacks=checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# Load the model from a file\n",
        "model = load_model('/content/best_model.h5')"
      ],
      "metadata": {
        "id": "WWnayWmgq38Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h=history.history\n",
        "h.keys()"
      ],
      "metadata": {
        "id": "x8-MWDZsrH_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(h['loss'])\n",
        "plt.plot(h['accuracy'])\n",
        "plt.show"
      ],
      "metadata": {
        "id": "VzeywSH8rvW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vgg implementation\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "# Define the model architecture\n",
        "model = Sequential()\n",
        "\n",
        "# Layer 1\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same', input_shape=(224,224,3)))\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "# Layer 2\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "# Layer 3\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "# Layer 4\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "# Layer 5\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "# Classification layer\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=4096, activation='relu'))\n",
        "model.add(Dense(units=4096, activation='relu'))\n",
        "model.add(Dense(units=3, activation='softmax'))\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Create data generators for training and validation\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "train_data = train_datagen.flow_from_directory(\n",
        "    directory='/content/drive/MyDrive/DATASET/',\n",
        "    target_size=(256, 256),\n",
        "    batch_size=26,\n",
        "    class_mode='categorical',\n",
        "    subset='training')\n",
        "\n",
        "val_data = train_datagen.flow_from_directory(\n",
        "    directory='/content/drive/MyDrive/DATASET/',\n",
        "    target_size=(256, 256),\n",
        "    batch_size=26,\n",
        "    class_mode='categorical',\n",
        "    subset='validation')\n",
        "\n",
        "# Train the model\n",
        "model.fit_generator(train_data, steps_per_epoch=12, epochs=10, validation_data=val_data)\n",
        "# Evaluate the model on the test set\n",
        "score = model.evaluate_generator(train_data, batch_size = 12)\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iqQVnR5zObFu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cc559621-d6bb-4a5e-ac4f-0b336041e9fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 520 images belonging to 3 classes.\n",
            "Found 0 images belonging to 3 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-8a085e036ea3>:69: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(train_data, steps_per_epoch=12, epochs=10, validation_data=val_data)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-8a085e036ea3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;31m# Evaluate the model on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2602\u001b[0m             \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2603\u001b[0m         )\n\u001b[0;32m-> 2604\u001b[0;31m         return self.fit(\n\u001b[0m\u001b[1;32m   2605\u001b[0m             \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2606\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential_3/flatten_3/Reshape' defined at (most recent call last):\n    File \"/usr/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.9/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelapp.py\", line 612, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/ioloop.py\", line 687, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/ioloop.py\", line 740, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 821, in inner\n      self.ctx_run(self.run)\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 782, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\", line 543, in execute_request\n      self.do_execute(\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 2854, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 3057, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-5-8a085e036ea3>\", line 69, in <module>\n      model.fit_generator(train_data, steps_per_epoch=12, epochs=10, validation_data=val_data)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 2604, in fit_generator\n      return self.fit(\n    File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1023, in train_step\n      y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/sequential.py\", line 413, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/layers/reshaping/flatten.py\", line 104, in call\n      return tf.reshape(inputs, flattened_shape)\nNode: 'sequential_3/flatten_3/Reshape'\nInput to reshape is a tensor with 851968 values, but the requested shape requires a multiple of 25088\n\t [[{{node sequential_3/flatten_3/Reshape}}]] [Op:__inference_train_function_5358]"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}